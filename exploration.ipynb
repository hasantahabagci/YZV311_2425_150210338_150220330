{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YZV311E Data Mining Project Data Preprocessing and Exploration\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasan Taha Bağcı - 150210338\n",
    "### Selman Turan Toker - 150220330\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.data_preprocess import *\n",
    "from utils.plots import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data and Exploring Main Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_catalog = pd.read_csv('data/product_catalog.csv')\n",
    "product_category_map = pd.read_csv('data/product_category_map.csv')\n",
    "transactions = pd.read_csv('data/transactions.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapes of the datasets are printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_catalog: (32776, 8)\n",
      "product_category_map: (4332, 2)\n",
      "transactions: (1071538, 4)\n"
     ]
    }
   ],
   "source": [
    "print('product_catalog:', product_catalog.shape)\n",
    "print('product_category_map:', product_category_map.shape)\n",
    "print('transactions:', transactions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = transactions.merge(product_catalog, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>quantity</th>\n",
       "      <th>manufacturer_id</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38769</td>\n",
       "      <td>3477</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>[74, 4109, 3867, 803, 4053]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42535</td>\n",
       "      <td>30474</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>229</td>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>[3459, 3738, 679, 1628, 4072]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42535</td>\n",
       "      <td>15833</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1318</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>[2973, 2907, 2749, 3357]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42535</td>\n",
       "      <td>20131</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>[30, 1515, 1760, 2932, 1287, 2615, 3727, 2450,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42535</td>\n",
       "      <td>4325</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>539</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>[3104, 1772, 2029, 1274, 3915, 888, 1118, 3882...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id purchase_date  quantity  manufacturer_id  \\\n",
       "0        38769        3477    2020-06-01         1              186   \n",
       "1        42535       30474    2020-06-01         1              193   \n",
       "2        42535       15833    2020-06-01         1             1318   \n",
       "3        42535       20131    2020-06-01         1              347   \n",
       "4        42535        4325    2020-06-01         1              539   \n",
       "\n",
       "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
       "0            6            0          196            0           45   \n",
       "1           10            3          229            3          132   \n",
       "2            4            1          455            0          108   \n",
       "3            4            0          291            3           44   \n",
       "4            6            0          303            0           45   \n",
       "\n",
       "                                          categories  \n",
       "0                        [74, 4109, 3867, 803, 4053]  \n",
       "1                      [3459, 3738, 679, 1628, 4072]  \n",
       "2                           [2973, 2907, 2749, 3357]  \n",
       "3  [30, 1515, 1760, 2932, 1287, 2615, 3727, 2450,...  \n",
       "4  [3104, 1772, 2029, 1274, 3915, 888, 1118, 3882...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Create a mapping from category_id to parent_category_id\n",
    "category_to_parent = product_category_map.set_index('category_id')['parent_category_id'].to_dict()\n",
    "\n",
    "# Function to map categories to their parent categories\n",
    "def get_parent_categories(categories_str):\n",
    "    if pd.isna(categories_str) or categories_str == '':\n",
    "        return []\n",
    "    # Convert string representation of list to an actual list\n",
    "    categories = ast.literal_eval(categories_str)\n",
    "    # Map each category to its parent\n",
    "    parent_categories = [category_to_parent.get(cat_id, None) for cat_id in categories]\n",
    "    # Remove None values if any category_id doesn't have a parent in the map\n",
    "    return [parent for parent in parent_categories if parent is not None]\n",
    "\n",
    "# Apply the function to add the parent_categories column\n",
    "final['parent_categories'] = final['categories'].apply(get_parent_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_category(row):\n",
    "    if pd.isna(row['category']):\n",
    "        return row['parent_categories']\n",
    "    return row['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id          0\n",
       "product_id           0\n",
       "purchase_date        0\n",
       "quantity             0\n",
       "manufacturer_id      0\n",
       "attribute_1          0\n",
       "attribute_2          0\n",
       "attribute_3          0\n",
       "attribute_4          0\n",
       "attribute_5          0\n",
       "categories           0\n",
       "parent_categories    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_nulls_removed = final.dropna()\n",
    "final_nulls_removed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_nulls_removed.to_csv('data/final_nulls_removed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_nulls_filled = final.fillna(fill_missing_category, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1071538 entries, 0 to 1071537\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count    Dtype \n",
      "---  ------             --------------    ----- \n",
      " 0   customer_id        1071538 non-null  object\n",
      " 1   product_id         1071538 non-null  object\n",
      " 2   purchase_date      1071538 non-null  object\n",
      " 3   quantity           1071538 non-null  object\n",
      " 4   manufacturer_id    1071538 non-null  object\n",
      " 5   attribute_1        1071538 non-null  object\n",
      " 6   attribute_2        1071538 non-null  object\n",
      " 7   attribute_3        1071538 non-null  object\n",
      " 8   attribute_4        1071538 non-null  object\n",
      " 9   attribute_5        1071538 non-null  object\n",
      " 10  categories         1071538 non-null  object\n",
      " 11  parent_categories  1071538 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 106.3+ MB\n"
     ]
    }
   ],
   "source": [
    "final_nulls_filled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_nulls_filled.drop(['quantity'], axis=1).reset_index(drop=True)\n",
    "y = final_nulls_filled['quantity'].reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions generated and saved to quantity_predictions.csv\n",
      "\n",
      "Prediction Statistics:\n",
      "Total Predictions: 10000\n",
      "Mean Predicted Quantity: 5.04\n",
      "Max Predicted Quantity: 32\n",
      "Min Predicted Quantity: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import ast\n",
    "import joblib\n",
    "\n",
    "# Load the training data\n",
    "train_df = pd.read_csv('data/final_nulls_removed.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Preprocess training data\n",
    "def parse_list_column(column):\n",
    "    return column.apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "train_df['categories'] = parse_list_column(train_df['categories'])\n",
    "train_df['parent_categories'] = parse_list_column(train_df['parent_categories'])\n",
    "\n",
    "# Feature engineering for training data\n",
    "def extract_first_category(categories):\n",
    "    return categories[0] if categories and len(categories) > 0 else -1\n",
    "\n",
    "train_df['first_category'] = train_df['categories'].apply(extract_first_category)\n",
    "train_df['first_parent_category'] = train_df['parent_categories'].apply(extract_first_category)\n",
    "\n",
    "# Prepare features\n",
    "features = [\n",
    "    'customer_id', 'product_id', 'manufacturer_id', \n",
    "    'attribute_1', 'attribute_2', 'attribute_3', \n",
    "    'attribute_4', 'attribute_5', \n",
    "    'first_category', 'first_parent_category'\n",
    "]\n",
    "test_features = features.copy()\n",
    "# Handle categorical features for training data\n",
    "label_encoders = {}\n",
    "for col in ['customer_id', 'product_id', 'manufacturer_id', \n",
    "            'first_category', 'first_parent_category']:\n",
    "    le = LabelEncoder()\n",
    "    train_df[f'{col}_encoded'] = le.fit_transform(train_df[col])\n",
    "    label_encoders[col] = le\n",
    "    features[features.index(col)] = f'{col}_encoded'\n",
    "\n",
    "# Prepare X and y for training\n",
    "X_train = train_df[features].values\n",
    "y_train = train_df['quantity'].values\n",
    "\n",
    "# Preprocess test data\n",
    "# Prepare features for test data\n",
    "\n",
    "\n",
    "# Encode test data features using the same label encoders\n",
    "for col in ['customer_id', 'product_id']:\n",
    "    col_encoded = f'{col}_encoded'\n",
    "    \n",
    "    # Safely encode test data using existing label encoders\n",
    "    def safe_encode(value):\n",
    "        try:\n",
    "            return label_encoders[col].transform([value])[0]\n",
    "        except ValueError:\n",
    "            # If the value is not in the original training set, assign a unique value\n",
    "            return len(label_encoders[col].classes_)\n",
    "    \n",
    "    test_df[col_encoded] = test_df[col].apply(safe_encode)\n",
    "    test_features[test_features.index(col)] = col_encoded\n",
    "\n",
    "# Add placeholder values for missing features\n",
    "test_df['first_category_encoded'] = -1\n",
    "test_df['first_parent_category_encoded'] = -1\n",
    "test_features[test_features.index('first_category')] = 'first_category_encoded'\n",
    "test_features[test_features.index('first_parent_category')] = 'first_parent_category_encoded'\n",
    "\n",
    "# Add placeholders for other numerical features\n",
    "for feature in ['manufacturer_id', 'attribute_1', 'attribute_2', \n",
    "                'attribute_3', 'attribute_4', 'attribute_5']:\n",
    "    if feature not in test_df.columns:\n",
    "        test_df[feature] = 0\n",
    "\n",
    "# Prepare X for test data\n",
    "X_test = test_df[test_features].values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_scaled)\n",
    "\n",
    "# Set XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predict quantities\n",
    "test_predictions = model.predict(dtest)\n",
    "\n",
    "# Round predictions to nearest integer (since quantity is typically whole numbers)\n",
    "test_predictions_rounded = np.round(test_predictions).astype(int)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = test_df[['id', 'customer_id', 'product_id']].copy()\n",
    "submission_df['prediction'] = test_predictions_rounded\n",
    "\n",
    "# Clip predictions to be non-negative\n",
    "submission_df['prediction'] = submission_df['prediction'].clip(lower=0)\n",
    "\n",
    "# Save predictions\n",
    "submission_df.to_csv('quantity_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions generated and saved to quantity_predictions.csv\")\n",
    "print(\"\\nPrediction Statistics:\")\n",
    "print(f\"Total Predictions: {len(submission_df)}\")\n",
    "print(f\"Mean Predicted Quantity: {submission_df['prediction'].mean():.2f}\")\n",
    "print(f\"Max Predicted Quantity: {submission_df['prediction'].max()}\")\n",
    "print(f\"Min Predicted Quantity: {submission_df['prediction'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
